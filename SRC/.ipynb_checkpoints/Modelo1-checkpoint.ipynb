{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importamos todas las librerias necesarias\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "#from keras.layers import Dense, Conv2D, Deconvolution2D, MaxPooling2D, Flatten\n",
    "from keras import layers as L\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la ruta donde se almacenan los datos del dataset\n",
    "path = '../Euro_Sat/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las imagenes del dataset serán los elementos de entrada, los elementos de salida serán a las clases a las que pertenecen esas fotos\n",
    "dic = {}\n",
    "entrada = []\n",
    "salida = []\n",
    "i = 0\n",
    "\n",
    "for ele in os.listdir(path):\n",
    "    if os.path.isdir(path+ele):\n",
    "        for file in os.listdir(path+ele):\n",
    "            im = Image.open(os.path.join(path,ele,file))\n",
    "            im_array = np.array(im)\n",
    "            entrada.append(im_array)\n",
    "            salida.append(i)\n",
    "        dic[i] = ele\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se representan las clases mediante la codificación ‘one hot\n",
    "clases_salida = to_categorical(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizamos las imágenes de modo que el rango de entrada a la CNN se encuentren entre 0 y 1\n",
    "entrada = np.array(entrada)\n",
    "entrada = entrada/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el conjunto de entrenamiento\n",
    "x_train, x_test, y_train, y_test = train_test_split(entrada, clases_salida, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                460850    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 484,944\n",
      "Trainable params: 484,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creamos el modelo de la red neuronal\n",
    "in_shape = x_train[0,:,:,:].shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=3, activation='relu', input_shape=in_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(len(dic), activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilamos el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21600 samples, validate on 5400 samples\n",
      "Epoch 1/25\n",
      "21600/21600 [==============================] - 69s 3ms/step - loss: 1.1886 - accuracy: 0.5504 - val_loss: 0.7636 - val_accuracy: 0.7274\n",
      "Epoch 2/25\n",
      "21600/21600 [==============================] - 72s 3ms/step - loss: 0.7606 - accuracy: 0.7259 - val_loss: 0.6244 - val_accuracy: 0.7746\n",
      "Epoch 3/25\n",
      "21600/21600 [==============================] - 68s 3ms/step - loss: 0.6638 - accuracy: 0.7629 - val_loss: 0.6251 - val_accuracy: 0.7743\n",
      "Epoch 4/25\n",
      "21600/21600 [==============================] - 69s 3ms/step - loss: 0.5931 - accuracy: 0.7889 - val_loss: 0.5792 - val_accuracy: 0.7900\n",
      "Epoch 5/25\n",
      "21600/21600 [==============================] - 68s 3ms/step - loss: 0.5556 - accuracy: 0.8040 - val_loss: 0.5230 - val_accuracy: 0.8128\n",
      "Epoch 6/25\n",
      "21600/21600 [==============================] - 68s 3ms/step - loss: 0.4978 - accuracy: 0.8215 - val_loss: 0.6175 - val_accuracy: 0.7741\n",
      "Epoch 7/25\n",
      "21600/21600 [==============================] - 69s 3ms/step - loss: 0.4602 - accuracy: 0.8371 - val_loss: 0.6978 - val_accuracy: 0.7628\n",
      "Epoch 8/25\n",
      "21600/21600 [==============================] - 69s 3ms/step - loss: 0.4178 - accuracy: 0.8501 - val_loss: 0.5186 - val_accuracy: 0.8193\n",
      "Epoch 9/25\n",
      "21600/21600 [==============================] - 69s 3ms/step - loss: 0.3942 - accuracy: 0.8593 - val_loss: 0.5518 - val_accuracy: 0.8165\n",
      "Epoch 10/25\n",
      "21600/21600 [==============================] - 68s 3ms/step - loss: 0.3711 - accuracy: 0.8683 - val_loss: 0.4763 - val_accuracy: 0.8446\n",
      "Epoch 11/25\n",
      "21600/21600 [==============================] - 70s 3ms/step - loss: 0.3250 - accuracy: 0.8858 - val_loss: 0.5690 - val_accuracy: 0.8117\n",
      "Epoch 12/25\n",
      "21600/21600 [==============================] - 71s 3ms/step - loss: 0.2882 - accuracy: 0.8991 - val_loss: 0.5006 - val_accuracy: 0.8420\n",
      "Epoch 13/25\n",
      "21600/21600 [==============================] - 68s 3ms/step - loss: 0.2635 - accuracy: 0.9062 - val_loss: 0.5276 - val_accuracy: 0.8419\n",
      "Epoch 14/25\n",
      "21600/21600 [==============================] - 73s 3ms/step - loss: 0.2534 - accuracy: 0.9126 - val_loss: 0.5817 - val_accuracy: 0.8283\n",
      "Epoch 15/25\n",
      "21600/21600 [==============================] - 70s 3ms/step - loss: 0.2226 - accuracy: 0.9204 - val_loss: 0.6762 - val_accuracy: 0.8028\n",
      "Epoch 16/25\n",
      "21600/21600 [==============================] - 74s 3ms/step - loss: 0.2002 - accuracy: 0.9284 - val_loss: 0.5888 - val_accuracy: 0.8250\n",
      "Epoch 17/25\n",
      "21600/21600 [==============================] - 67s 3ms/step - loss: 0.1721 - accuracy: 0.9392 - val_loss: 0.6362 - val_accuracy: 0.8309\n",
      "Epoch 18/25\n",
      "21600/21600 [==============================] - 68s 3ms/step - loss: 0.1706 - accuracy: 0.9398 - val_loss: 0.6524 - val_accuracy: 0.8326\n",
      "Epoch 19/25\n",
      "21600/21600 [==============================] - 69s 3ms/step - loss: 0.1472 - accuracy: 0.9492 - val_loss: 0.7160 - val_accuracy: 0.8309\n",
      "Epoch 20/25\n",
      "21600/21600 [==============================] - 71s 3ms/step - loss: 0.1376 - accuracy: 0.9522 - val_loss: 0.6872 - val_accuracy: 0.8433\n",
      "Epoch 21/25\n",
      "21600/21600 [==============================] - 69s 3ms/step - loss: 0.1446 - accuracy: 0.9512 - val_loss: 0.6987 - val_accuracy: 0.8381\n",
      "Epoch 22/25\n",
      "21600/21600 [==============================] - 70s 3ms/step - loss: 0.1173 - accuracy: 0.9599 - val_loss: 0.8265 - val_accuracy: 0.8207\n",
      "Epoch 23/25\n",
      "21600/21600 [==============================] - 70s 3ms/step - loss: 0.1080 - accuracy: 0.9635 - val_loss: 0.8034 - val_accuracy: 0.8243\n",
      "Epoch 24/25\n",
      "21600/21600 [==============================] - 70s 3ms/step - loss: 0.0935 - accuracy: 0.9670 - val_loss: 0.8170 - val_accuracy: 0.8311\n",
      "Epoch 25/25\n",
      "21600/21600 [==============================] - 69s 3ms/step - loss: 0.1063 - accuracy: 0.9636 - val_loss: 0.9308 - val_accuracy: 0.8157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c1b4bc9080>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos el modelo\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.42%\n"
     ]
    }
   ],
   "source": [
    "#Sacamos el accuracy del modelo\n",
    "scores = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Guardamos el modelo para poder usarlo cuando se quiera\n",
    "model_json = model.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizamos las predicciones de varias muestras de prueba y las comparamos con las clases a las que realmente pertenecen.\n",
    "prueba_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for prueba in prueba_test[19]:\n",
    "    print(round(prueba,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = [dic[np.argmax(p)] for p in prueba_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "suelos_test = [dic[np.argmax(s)] for s in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = suelos_test[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pred_test[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_Actual</th>\n",
       "      <th>y_Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Highway</td>\n",
       "      <td>Highway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AnnualCrop</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Forest</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AnnualCrop</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>SeaLake</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>AnnualCrop</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Forest</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Forest</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               y_Actual           y_Predicted\n",
       "0            Industrial            Industrial\n",
       "1               Highway               Highway\n",
       "2            AnnualCrop            AnnualCrop\n",
       "3                Forest                Forest\n",
       "4            AnnualCrop            AnnualCrop\n",
       "5               SeaLake               SeaLake\n",
       "6            AnnualCrop            AnnualCrop\n",
       "7                Forest                Forest\n",
       "8  HerbaceousVegetation  HerbaceousVegetation\n",
       "9                Forest                Forest"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparamos los datos de entrenamiento con los predecidos\n",
    "import pandas as pd\n",
    "\n",
    "d = {'y_Actual': s,\n",
    "        'y_Predicted': t}\n",
    "\n",
    "dat = pd.DataFrame(data=d)\n",
    "dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 5, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 7, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 2, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 3, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 4]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(s, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "my_image_resized = plt.imread(\"../Pruebas/test_sea.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
